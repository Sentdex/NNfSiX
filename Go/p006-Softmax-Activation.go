package main

import (
	"fmt"
	"math"
	"math/rand"

	"gonum.org/v1/gonum/mat"
)

// LayerDense represents a layer
type LayerDense struct {
	Weights *mat.Dense
	Biases  *mat.Dense
	Output  *mat.Dense
}

// NewLayerDense creates layer generated by random numbers based on given number of inputs and neurons
func NewLayerDense(numberOfInputs, numberOfNeurons int) *LayerDense {
	randData := make([]float64, numberOfInputs*numberOfNeurons)
	for i := range randData {
		randData[i] = 0.10 * rand.NormFloat64()
	}
	return &LayerDense{
		Weights: mat.NewDense(numberOfInputs, numberOfNeurons, randData),
		Biases:  mat.NewDense(1, numberOfNeurons, nil),
	}
}

// Forward forwards the input
func (l *LayerDense) Forward(input *mat.Dense) {
	var mulRes mat.Dense
	mulRes.Mul(input, l.Weights)
	l.Output = mat.NewDense(mulRes.RawMatrix().Rows, mulRes.RawMatrix().Cols, nil)
	for i := 0; i < mulRes.RawMatrix().Rows; i++ {
		for j := 0; j < mulRes.RawMatrix().Cols; j++ {
			output := mulRes.At(i, j) + l.Biases.At(0, j)
			l.Output.Set(i, j, output)
		}
	}
}

// ActivationRelu represents the ReLU activation function result
type ActivationRelu struct {
	Output *mat.Dense
}

// NewActivationRelu returns ActivationRelu with nil Output
func NewActivationRelu() *ActivationRelu {
	return &ActivationRelu{}
}

// Forward forwards the activation result
func (a *ActivationRelu) Forward(input *mat.Dense) {
	a.Output = mat.NewDense(input.RawMatrix().Rows, input.RawMatrix().Cols, nil)
	for i := 0; i < input.RawMatrix().Rows; i++ {
		for j := 0; j < input.RawMatrix().Cols; j++ {
			x := input.At(i, j)
			if x > 0 {
				a.Output.Set(i, j, x)
			} else {
				a.Output.Set(i, j, 0)
			}
		}
	}
}


// ActivationSoftmax represents the ReLU activation function result
type ActivationSoftmax struct {
	Output *mat.Dense
}

// NewActivationSoftmax returns ActivationSoftmax with nil Output
func NewActivationSoftmax() *ActivationSoftmax {
	return &ActivationSoftmax{}
}

// Forward forwards the activation result
func (a *ActivationSoftmax) Forward(input *mat.Dense) {
	var rows int = input.RawMatrix().Rows
	var cols int = input.RawMatrix().Cols

	maxes := mat.NewVecDense(rows, nil)
	exp_values := mat.NewDense(rows, cols, nil)

	for i := 0; i < rows; i++ {
		var curr_max float64 = math.Inf(-1)
		for j := 0; j < cols; j++ {
			if curr_max < input.At(i, j) {
				curr_max = input.At(i, j)
			}
		}
	}

	for i := 0; i < rows; i++ {
		for j := 0; j < cols; j++ {
			exp_values.Set(i, j, math.Pow(math.E, input.At(i, j)-maxes.AtVec(i)))
		}
	}

	probabilities := mat.NewDense(rows, cols, nil)

	for i := 0; i < rows; i++ {
		var curr_sum float64 = 0
		for j := 0; j < cols; j++ {
			curr_sum += exp_values.At(i, j)
		}
		for j := 0; j < cols; j++ {
			probabilities.Set(i, j, exp_values.At(i, j)/curr_sum)
		}
	}

	a.Output = probabilities
}


func main() {
	rand.Seed(0)
	X, _ := NewSpiralData(100, 3)

	dense1 := NewLayerDense(2, 3)
	activation1 := NewActivationRelu()
	dense2 := NewLayerDense(3, 3)
	activation2 := NewActivationSoftmax()

	dense1.Forward(X)
	activation1.Forward(dense1.Output)
	dense2.Forward(activation1.Output)
	activation2.Forward(dense2.Output)
	fmt.Println(activation2.Output)
}

// NewSpiralData generates spiral data. see: https://cs231n.github.io/neural-networks-case-study/
func NewSpiralData(numberOfPoints, numberOfClasses int) (*mat.Dense, *mat.Dense) {
	X := mat.NewDense(numberOfPoints*numberOfClasses, 2, nil)
	y := mat.NewDense(numberOfPoints*numberOfClasses, 1, nil)

	for c := 0; c < numberOfClasses; c++ {
		radius := linspace(0, 1, numberOfPoints)
		t := linspace(float64(c*4), float64((c+1)*4), numberOfPoints)
		for i := range t {
			t[i] += 0.2 * rand.NormFloat64()
		}
		for i := 0; i < numberOfPoints; i++ {
			X.Set(c*numberOfPoints+i, 0, radius[i]*math.Sin(t[i]*2.5))
			X.Set(c*numberOfPoints+i, 1, radius[i]*math.Cos(t[i]*2.5))
			y.Set(c*numberOfPoints+i, 0, float64(c))
		}
	}

	return X, y
}

func linspace(start, end float64, num int) []float64 {
	result := make([]float64, num)
	step := (end - start) / float64(num-1)
	for i := range result {
		result[i] = start + float64(i)*step
	}
	return result
}
